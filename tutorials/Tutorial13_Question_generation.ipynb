{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Question Generation\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deepset-ai/haystack/blob/master/tutorials/Tutorial13_Question_generation.ipynb)\n",
    "\n",
    "This is a bare bones tutorial showing what is possible with the QuestionGenerator Nodes and Pipelines which automatically\n",
    "generate questions which the question generation model thinks can be answered by a given document."
   ],
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare environment\n",
    "\n",
    "#### Colab: Enable the GPU runtime\n",
    "Make sure you enable the GPU runtime to experience decent speed in this tutorial.  \n",
    "**Runtime -> Change Runtime type -> Hardware accelerator -> GPU**\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/deepset-ai/haystack/master/docs/_src/img/colab_gpu_runtime.jpg\">"
   ],
   "metadata": {
    "id": "yaaKv3_ZN-gb",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Install needed libraries\n",
    "\n",
    "!pip install grpcio-tools==1.34.1\n",
    "!pip install git+https://github.com/deepset-ai/haystack.git\n",
    "\n",
    "# If you run this notebook on Google Colab, you might need to\n",
    "# restart the runtime after installing haystack."
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Imports needed to run this notebook\n",
    "\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from haystack.nodes import QuestionGenerator, ElasticsearchRetriever, FARMReader\n",
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "from haystack.pipelines import QuestionGenerationPipeline, RetrieverQuestionGenerationPipeline, QuestionAnswerGenerationPipeline\n",
    "from haystack.utils import launch_es"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's start an Elasticsearch instance with one of the options below:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Option 1: Start Elasticsearch service via Docker\n",
    "launch_es()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8c25bfa0f71fbdaab81f7fca0820e49a47b528786bf1cd7389259b1d74a9366a\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Option 2: In Colab / No Docker environments: Start Elasticsearch from source\n",
    "! wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.2-linux-x86_64.tar.gz -q\n",
    "! tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz\n",
    "! chown -R daemon:daemon elasticsearch-7.9.2\n",
    "\n",
    "import os\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "es_server = Popen(['elasticsearch-7.9.2/bin/elasticsearch'],\n",
    "                   stdout=PIPE, stderr=STDOUT,\n",
    "                   preexec_fn=lambda: os.setuid(1)  # as daemon\n",
    "                  )\n",
    "# wait until ES has started\n",
    "! sleep 30"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's initialize some core components"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "text1 = \"Python is an interpreted, high-level, general-purpose programming language. Created by Guido van Rossum and first released in 1991, Python's design philosophy emphasizes code readability with its notable use of significant whitespace.\"\n",
    "text2 = \"Princess Arya Stark is the third child and second daughter of Lord Eddard Stark and his wife, Lady Catelyn Stark. She is the sister of the incumbent Westerosi monarchs, Sansa, Queen in the North, and Brandon, King of the Andals and the First Men. After narrowly escaping the persecution of House Stark by House Lannister, Arya is trained as a Faceless Man at the House of Black and White in Braavos, using her abilities to avenge her family. Upon her return to Westeros, she exacts retribution for the Red Wedding by exterminating the Frey male line.\"\n",
    "text3 = \"Dry Cleaning are an English post-punk band who formed in South London in 2018.[3] The band is composed of vocalist Florence Shaw, guitarist Tom Dowse, bassist Lewis Maynard and drummer Nick Buxton. They are noted for their use of spoken word primarily in lieu of sung vocals, as well as their unconventional lyrics. Their musical stylings have been compared to Wire, Magazine and Joy Division.[4] The band released their debut single, 'Magic of Meghan' in 2019. Shaw wrote the song after going through a break-up and moving out of her former partner's apartment the same day that Meghan Markle and Prince Harry announced they were engaged.[5] This was followed by the release of two EPs that year: Sweet Princess in August and Boundary Road Snacks and Drinks in October. The band were included as part of the NME 100 of 2020,[6] as well as DIY magazine's Class of 2020.[7] The band signed to 4AD in late 2020 and shared a new single, 'Scratchcard Lanyard'.[8] In February 2021, the band shared details of their debut studio album, New Long Leg. They also shared the single 'Strong Feelings'.[9] The album, which was produced by John Parish, was released on 2 April 2021.[10]\"\n",
    "\n",
    "docs = [{\"content\": text1},\n",
    "        {\"content\": text2},\n",
    "        {\"content\": text3}]\n",
    "\n",
    "# Initialize document store and write in the documents\n",
    "document_store = ElasticsearchDocumentStore()\n",
    "document_store.write_documents(docs)\n",
    "\n",
    "# Initialize Question Generator\n",
    "question_generator = QuestionGenerator()"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question Generation Pipeline\n",
    "\n",
    "The most basic version of a question generator pipeline takes a document as input and outputs generated questions\n",
    "which the the document can answer."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "question_generation_pipeline = QuestionGenerationPipeline(question_generator)\n",
    "for idx, document in enumerate(document_store):\n",
    "        \n",
    "    print(f\"\\n * Generating questions for document {idx}: {document.content[:50]}...\")\n",
    "    result = question_generation_pipeline.run(documents=[document])\n",
    "\n",
    "    print(\"Generated questions:\")\n",
    "    for result in result[\"generated_questions\"]:\n",
    "        for question in result[\"questions\"]:\n",
    "            print(f\" - {question}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " * Generating questions for document 0: Python is an interpreted, high-level, general-purp...\n",
      "Generated questions:\n",
      " -  Who created Python?\n",
      " -  When was Python first released?\n",
      " -  What is Python's design philosophy?\n",
      "\n",
      " * Generating questions for document 1: Princess Arya Stark is the third child and second ...\n",
      "Generated questions:\n",
      " -  Who is the third child and second daughter of Lord Eddard Stark and his wife, Lady Catelyn Stark?\n",
      " -  Princess Arya Stark is the sister of what Westerosi monarchs?\n",
      " -  What is Sansa, Queen in the North, and Brandon, King of the Andals?\n",
      " -  What is Arya trained as?\n",
      " -  Where is the House of Black and White located?\n",
      " -  What is the name of the first men?\n",
      " -  What is the name of the line that Frey exterminates?\n",
      " -  Where does the Red Wedding take place?\n",
      "\n",
      " * Generating questions for document 2: Dry Cleaning are an English post-punk band who for...\n",
      "Generated questions:\n",
      " -  What is the name of the English post-punk band that formed in South London in 2018?\n",
      " -  Who is the vocalist of Dry Cleaning?\n",
      " -  Where did Dry Cleaning form?\n",
      " -  What does the band use instead of sung vocals?\n",
      " -  What is the name of the band's debut single?\n",
      " -  What was Shaw's first song called?\n",
      " -  When did Shaw write the song Magic of Meghan?\n",
      " -  When did Meghan Markle and Prince Harry announce they were engaged?\n",
      " -  What was the name of the two EPs released in August?\n",
      " -  When was Boundary Road Snacks and Drinks released?\n",
      " -  When did Boundary Road Snacks and Drinks release their album?\n",
      " -  When did the band sign to 4AD?\n",
      " -  What was the name of the new single that the band shared in February 2021?\n",
      " -  Which magazine included the band in the Class of 2020?\n",
      " -  What was the name of the new single released in February 2021?\n",
      " -  Who produced the album New Long Leg?\n",
      " -  When was the album released?\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Retriever Question Generation Pipeline\n",
    "\n",
    "This pipeline takes a query as input. It retrieves relevant documents and then generates questions based on these."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "retriever = ElasticsearchRetriever(document_store=document_store)\n",
    "rqg_pipeline = RetrieverQuestionGenerationPipeline(retriever, question_generator)\n",
    "\n",
    "print(f\"\\n * Generating questions for documents matching the query 'Arya Stark'\")\n",
    "result = rqg_pipeline.run(query=\"Arya Stark\")\n",
    "\n",
    "print(\"Generated questions:\")\n",
    "for result in result[\"generated_questions\"]:\n",
    "    for question in result[\"questions\"]:\n",
    "        print(f\" - {question}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " * Generating questions for documents matching the query 'Arya Stark'\n",
      "Generated questions:\n",
      " -  Who is the third child and second daughter of Lord Eddard Stark and his wife, Lady Catelyn Stark?\n",
      " -  Princess Arya Stark is the sister of what Westerosi monarchs?\n",
      " -  What is Sansa, Queen in the North, and Brandon, King of the Andals?\n",
      " -  What is Arya trained as?\n",
      " -  Where is the House of Black and White located?\n",
      " -  What is the name of the first men?\n",
      " -  What is the name of the line that Frey exterminates?\n",
      " -  Where does the Red Wedding take place?\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question Answer Generation Pipeline\n",
    "\n",
    "This pipeline takes a document as input, generates questions on it, and attempts to answer these questions using\n",
    "a Reader model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "reader = FARMReader(\"deepset/roberta-base-squad2\")\n",
    "qag_pipeline = QuestionAnswerGenerationPipeline(question_generator, reader)\n",
    "for idx, document in enumerate(tqdm(document_store)):\n",
    "\n",
    "    print(f\"\\n * Generating questions and answers for document {idx}: {document.content[:20]}...\")\n",
    "    result = qag_pipeline.run(documents=[document])\n",
    "\n",
    "    for pair in result[\"results\"]:\n",
    "        print(f\" - Q:{pair['query']}\")\n",
    "        for answer in pair[\"answers\"]:\n",
    "            print(f\"      A: {answer.answer}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at deepset/roberta-base-squad2 were not used when initializing RobertaModel: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at deepset/roberta-base-squad2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " * Generating questions and answers for document 0: Python is an interpr...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.96 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.99 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.00 Batches/s]\n",
      "1it [00:05,  5.68s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " - Q: Who created Python?\n",
      "      A: Guido van Rossum\n",
      " - Q: When was Python first released?\n",
      "      A: 1991\n",
      " - Q: What is Python's design philosophy?\n",
      "      A: emphasizes code readability\n",
      "\n",
      " * Generating questions and answers for document 1: Princess Arya Stark ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.63 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.76 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.59 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.99 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.99 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.01 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.00 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.98 Batches/s]\n",
      "2it [00:27, 15.46s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " - Q: Who is the third child and second daughter of Lord Eddard Stark and his wife, Lady Catelyn Stark?\n",
      "      A: Princess Arya Stark\n",
      " - Q: Princess Arya Stark is the sister of what Westerosi monarchs?\n",
      "      A: Sansa, Queen in the North, and Brandon, King of the Andals and the First Men\n",
      " - Q: What is Sansa, Queen in the North, and Brandon, King of the Andals?\n",
      "      A: sister\n",
      " - Q: What is Arya trained as?\n",
      "      A: Faceless Man\n",
      " - Q: Where is the House of Black and White located?\n",
      "      A: Braavos\n",
      " - Q: What is the name of the first men?\n",
      "      A: Brandon\n",
      " - Q: What is the name of the line that Frey exterminates?\n",
      "      A: Frey male line\n",
      " - Q: Where does the Red Wedding take place?\n",
      "      A: Westeros\n",
      "\n",
      " * Generating questions and answers for document 2: Dry Cleaning are an ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Inferencing Samples: 100%|██████████| 1/1 [00:01<00:00,  1.06s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:01<00:00,  1.06s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.04 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.04 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.01 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:01<00:00,  1.01s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:01<00:00,  1.16s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.03 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.03 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.05 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.05 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.05 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.06 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:01<00:00,  1.16s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.03 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.04 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.04 Batches/s]\n",
      "3it [01:18, 26.01s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " - Q: What is the name of the English post-punk band that formed in South London in 2018?\n",
      "      A: Dry Cleaning\n",
      "      A: Boundary Road Snacks and Drinks\n",
      " - Q: Who is the vocalist of Dry Cleaning?\n",
      "      A: Florence Shaw\n",
      "      A: ghan Markle and Prince Harry announced they were engaged.[5] This was followed by the release of two EPs that year: Sweet Princess in August and Boundary Road Snacks and Drinks in October. The band were included as part of the NME 100 of 2020,[6] as well as DIY magazine's Class of 2020.[7] The band signed to 4AD in late 2020 and shared a new single, 'Scratchcard Lanyard'.[8] In February 2021, the band shared details of their debut studio album, New Long Leg. They also shared the single 'Strong Feelings'.[9] The album, which was produced by John Parish\n",
      " - Q: Where did Dry Cleaning form?\n",
      "      A: South London\n",
      "      A: Boundary Road\n",
      " - Q: What does the band use instead of sung vocals?\n",
      "      A: spoken word\n",
      "      A: 2020,[6] as well as DIY magazine's Class of 2020.[7] The band signed to 4AD in late 2020 and shared a new single, 'Scratchcard Lanyard'.[8] In February 2021, the band shared details of their debut studio album, New Long Leg. They also shared the single 'Strong Feelings'.[9]\n",
      " - Q: What is the name of the band's debut single?\n",
      "      A: Magic of Meghan\n",
      "      A: Scratchcard Lanyard\n",
      " - Q: What was Shaw's first song called?\n",
      "      A: Magic of Meghan\n",
      "      A: Scratchcard Lanyard\n",
      " - Q: When did Shaw write the song Magic of Meghan?\n",
      "      A: after going through a break-up and moving out of her former partner's apartment the same day that Meghan Markle and Prince Harry announced they were engaged\n",
      "      A: 2020\n",
      " - Q: When did Meghan Markle and Prince Harry announce they were engaged?\n",
      "      A: August\n",
      "      A: the same day\n",
      " - Q: What was the name of the two EPs released in August?\n",
      "      A: Sweet Princess\n",
      " - Q: When was Boundary Road Snacks and Drinks released?\n",
      "      A: October\n",
      " - Q: When did Boundary Road Snacks and Drinks release their album?\n",
      "      A: October\n",
      " - Q: When did the band sign to 4AD?\n",
      "      A: late 2020\n",
      " - Q: What was the name of the new single that the band shared in February 2021?\n",
      "      A: Strong Feelings\n",
      "      A: Scratchcard Lanyard\n",
      " - Q: Which magazine included the band in the Class of 2020?\n",
      "      A: DIY\n",
      " - Q: What was the name of the new single released in February 2021?\n",
      "      A: Strong Feelings\n",
      "      A: Scratchcard Lanyard\n",
      " - Q: Who produced the album New Long Leg?\n",
      "      A: John Parish\n",
      "      A: 4AD\n",
      " - Q: When was the album released?\n",
      "      A: 2 April 2021\n",
      "      A: February 2021\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## About us\n",
    "\n",
    "This [Haystack](https://github.com/deepset-ai/haystack/) notebook was made with love by [deepset](https://deepset.ai/) in Berlin, Germany\n",
    "\n",
    "We bring NLP to the industry via open source!\n",
    "Our focus: Industry specific language models & large scale QA systems.\n",
    "\n",
    "Some of our other work:\n",
    "- [German BERT](https://deepset.ai/german-bert)\n",
    "- [GermanQuAD and GermanDPR](https://deepset.ai/germanquad)\n",
    "- [FARM](https://github.com/deepset-ai/FARM)\n",
    "\n",
    "Get in touch:\n",
    "[Twitter](https://twitter.com/deepset_ai) | [LinkedIn](https://www.linkedin.com/company/deepset-ai/) | [Slack](https://haystack.deepset.ai/community/join) | [GitHub Discussions](https://github.com/deepset-ai/haystack/discussions) | [Website](https://deepset.ai)\n",
    "\n",
    "By the way: [we're hiring!](https://www.deepset.ai/jobs)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}